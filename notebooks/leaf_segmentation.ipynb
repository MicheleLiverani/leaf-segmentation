{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1ae39ff",
      "metadata": {
        "id": "a1ae39ff"
      },
      "source": [
        "# Segment leaf images with with SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NnR79rbnpK_4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NnR79rbnpK_4",
        "outputId": "929877c2-45f9-436a-f8bc-5be5111e295b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a4b25c",
      "metadata": {
        "id": "b4a4b25c"
      },
      "source": [
        "The Segment Anything Model (SAM) predicts object masks given prompts that indicate the desired object. The model first converts the image into an image embedding that allows high quality masks to be efficiently produced from a prompt.\n",
        "\n",
        "The `SamPredictor` class provides an easy interface to the model for prompting the model. It allows the user to first set an image using the `set_image` method, which calculates the necessary image embeddings. Then, prompts can be provided via the `predict` method to efficiently predict masks from those prompts. The model can take as input both point and box prompts, as well as masks from the previous iteration of prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644532a8",
      "metadata": {
        "id": "644532a8"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fabfee",
      "metadata": {
        "id": "07fabfee"
      },
      "source": [
        "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea65efc",
      "metadata": {
        "id": "5ea65efc"
      },
      "outputs": [],
      "source": [
        "using_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91dd9a89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91dd9a89",
        "outputId": "371d3e7f-f81a-4f6f-d7dd-51084f1d3be7"
      },
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be845da",
      "metadata": {
        "id": "0be845da"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33681dd1",
      "metadata": {
        "id": "33681dd1"
      },
      "source": [
        "Necessary imports and helper functions for displaying points, boxes, and masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b28288",
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29bc90d5",
      "metadata": {
        "id": "29bc90d5"
      },
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b228b8",
      "metadata": {
        "id": "98b228b8"
      },
      "source": [
        "## Selecting objects with SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb1927b",
      "metadata": {
        "id": "0bb1927b"
      },
      "source": [
        "First, load the SAM model and predictor. Change the path below to point to the SAM checkpoint. Running on CUDA and using the default model are recommended for best results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e28150b",
      "metadata": {
        "id": "7e28150b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23842fb2",
      "metadata": {
        "id": "23842fb2"
      },
      "source": [
        "## Leaves segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-5CQDoRts3xp",
      "metadata": {
        "id": "-5CQDoRts3xp"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/Coding/data/processed\"\n",
        "save_path = \"/content/drive/MyDrive/Coding/data/red\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2e4f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3c2e4f6b",
        "outputId": "2380bb0d-4c14-4684-d3ec-cddb65ef40fb"
      },
      "outputs": [],
      "source": [
        "data_path = Path(data_path)\n",
        "save_path = Path(save_path)\n",
        "\n",
        "# open the json with the points\n",
        "with open(data_path / \"points.json\", \"r\") as f:\n",
        "    points = json.load(f)\n",
        "\n",
        "# iterate through all the images\n",
        "for image_path in data_path.rglob(\"*.jpg\"):\n",
        "\n",
        "    # get the image name to access to the points\n",
        "    image_name = image_path.stem\n",
        "\n",
        "    # create the save dir\n",
        "    dir_path = image_path.parent\n",
        "    exp_name = dir_path.name\n",
        "    save_dir = save_path / exp_name\n",
        "    save_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    print(exp_name, image_name)\n",
        "\n",
        "    # read the image\n",
        "    image = cv2.imread(str(image_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # embed the image\n",
        "    predictor.set_image(image)\n",
        "\n",
        "    # get the points\n",
        "    input_point = []\n",
        "    input_label = []\n",
        "    for point in points[image_name]:\n",
        "        input_point.append([point[\"x\"], point[\"y\"]])\n",
        "        input_label.append(point[\"label\"])\n",
        "    input_point = np.array(input_point)\n",
        "    input_label = np.array(input_label)\n",
        "\n",
        "    # show the image with the points\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(image)\n",
        "    show_points(input_point, input_label, plt.gca())\n",
        "    plt.axis('on')\n",
        "    plt.show()\n",
        "\n",
        "    masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=False\n",
        "    )\n",
        "\n",
        "    red_image = image.copy()\n",
        "\n",
        "    red_image[np.where(masks[0])] = [255, 0, 0]\n",
        "\n",
        "    # covert the array to a PIL image\n",
        "    colored_img = Image.fromarray(red_image)\n",
        "    colored_img.save(save_dir / f\"{image_name}.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
